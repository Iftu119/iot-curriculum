{
 "cells": [
  {
   "source": [
    "# Speech to Text using a Raspberry Pi\n",
    "\n",
    "This lab shows how to use the [Azure Cognitive Services speech service](https://azure.microsoft.com/services/cognitive-services/speech-services/?WT.mc_id=iotcurriculum-github-jabenn) on a Raspberry Pi. You will need a Cognitive Services speech resource to use this lab, and you can find all the instructions to get set up in the [README file](https://github.com/microsoft/iot-curriculum/tree/main/labs/ai-edge/speech-to-text).\n",
    "\n",
    "This lab records 10 seconds of speech, then sends it to the Speech service to convert to text.\n",
    "\n",
    "There is currently no SDK support for this speech service on ARM32 Linux, so this lab uses the REST APIs.\n",
    "\n",
    "To use this Notebook, read each documentation cell, then select Run to run each code cell. The output of the code cells will be shown below. You can read more on running Jupyter Notebooks in the [Jupyter Notebooks documentation](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First the options for the Speech cognitive service need to be configured.\n",
    "* Set the `KEY` variable to be the key of your speech resource\n",
    "* Set the `ENDPOINT` variable to be your endpoint.\n",
    "* Set the `LANGUAGE` variable to the language you will be speaking in. You can find details on the supported langauges in the [Language and voice support for the Speech service documentation](https://docs.microsoft.com/azure/cognitive-services/speech-service/language-support?WT.mc_id=iotcurriculum-github-jabenn)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = \"YOUR_SPEECH_KEY\"\n",
    "ENDPOINT = \"YOUR_SPEECH_ENDPOINT\"\n",
    "LANGUAGE = \"en-US\""
   ]
  },
  {
   "source": [
    "To access the microphone, a few Python packages need to be installed:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install cffi\n",
    "!pip3 install pyaudio\n",
    "!pip3 install sounddevice\n",
    "!pip3 install soundfile\n",
    "!pip3 install scipy"
   ]
  },
  {
   "source": [
    "Another package is needed to make calls to the REST API:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install requests"
   ]
  },
  {
   "source": [
    "Once the packages are installed, they need to be imported to be available to the Python code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import requests\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "source": [
    "Before audio can be captured, some configuration needs to be set up. The sample rate needs to be set to 16khz, and the sample length needs to be set to 10 seconds.\n",
    "\n",
    "> If you want to record for longer, change the value of `sample_len` to the time in seconds that you want to record for."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Speech to Text Cognitive Service API currently only supports a 16000hz samplerate\n",
    "sample_rate = 16000\n",
    "\n",
    "# Length of the audio sample in seconds\n",
    "sample_len = 10"
   ]
  },
  {
   "source": [
    "Now capture the audio. Once you start running this cell, speak into the microphone for 10 seconds."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the speech sample\n",
    "speech_sample = sd.rec(int(sample_len * sample_rate), samplerate=sample_rate, channels=1)\n",
    "\n",
    "print(\"Start speaking now!\")\n",
    "\n",
    "# Wait for the recording to stop after the specified number of seconds\n",
    "sd.wait()\n",
    "\n",
    "# Let the user know the recording is done\n",
    "print(\"Recorded!\")"
   ]
  },
  {
   "source": [
    "The speech sample now needs to be saved to disk."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of audio file to save sample\n",
    "filename = \"speech_to_text_rec.wav\"\n",
    "\n",
    "# Save speech sample as a .wav file\n",
    "write(filename, sample_rate, speech_sample)"
   ]
  },
  {
   "source": [
    "The endpoint that comes from the Cognitive Service is designed to issue access tokens so you can then make the relevant API call. The endpoint is called passing in the API key to get back a bearer token and URL to use for the actual API calls."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the request headers with the API key\n",
    "headers = {\n",
    "    \"Ocp-Apim-Subscription-Key\": KEY\n",
    "}\n",
    "\n",
    "# Make a POST request to the endpoint to get the token\n",
    "response = requests.post(ENDPOINT, headers=headers)\n",
    "access_token = str(response.text)"
   ]
  },
  {
   "source": [
    "Next step is to make the REST API call, uploading the file with the speech data to a URL. The URL is built by extracting the location from the API endpoint and using that to build a new URL pointing to the speech service itself. The bearer token is set in the request header, the body of the request is the file that was just written. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the location from the endpoint by removing the http protocol and getting the section before the first .\n",
    "location = ENDPOINT.split(\"//\")[-1].split(\".\")[0]\n",
    "\n",
    "# Build the URL from the endpoint\n",
    "url = \"https://\" + location + \".stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1\"\n",
    "\n",
    "# Set the headers to include the Cognitive Services resource key\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer \" + access_token,\n",
    "    \"Content-Type\": \"audio/wav; codecs=audio/pcm; samplerate=16000\",\n",
    "    \"Accept\": \"application/json;text/xml\"\n",
    "}\n",
    "\n",
    "# Configure the language parameter for the call\n",
    "params = {\n",
    "    \"language\": LANGUAGE\n",
    "}\n",
    "\n",
    "# Make the request passing the file as the body\n",
    "response = requests.post(url, headers=headers, params=params, data=open(filename, \"rb\"))"
   ]
  },
  {
   "source": [
    "The `response` contains the result of the speech to text call as JSON. If the call was successful, it will return an object with a `RecognitionStatus` of `Success`, and a `DisplayText` with the speech converted to text."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the response to JSON\n",
    "responsejson = json.loads(response.text)\n",
    "\n",
    "if responsejson[\"RecognitionStatus\"] == \"Success\":\n",
    "    print('Results from Speech to Text API:')\n",
    "    print(responsejson['DisplayText'])\n",
    "else\n",
    "    print(\"No speech detected\")\n",
    "    print(\"The raw response is:\")\n",
    "    print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}